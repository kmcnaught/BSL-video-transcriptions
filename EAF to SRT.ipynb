{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "390c5b4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using time offset: 2960\n",
      "Extracting english subtitles\n",
      "Found 2.26 minutes of subtitles from 00:00:02,960 to 00:02:18,597 \n",
      "Extracting BSL subtitles\n",
      "LBUOY-ONE (points to list)\n",
      "LBUOY-FIVE (points to list)\n",
      "LBUOY-FIVE (points to list)\n",
      "LBUOY-ONE (points to list)\n",
      "LBUOY-FIVE (points to list)\n",
      "LBUOY-FIVE (points to list)\n",
      "Found 1.15 minutes of subtitles from 00:00:02,973 to 00:01:12,040 \n"
     ]
    }
   ],
   "source": [
    "import pympi\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "def get_all_time_offsets(eaf_file):\n",
    "    \n",
    "    offsets = []\n",
    "    eaf = pympi.Elan.Eaf(eaf_file)    \n",
    "\n",
    "    for media_descriptor in eaf.media_descriptors:\n",
    "        TIME_ORIGIN='TIME_ORIGIN'\n",
    "        if (TIME_ORIGIN in media_descriptor):\n",
    "            offsets.append(int((media_descriptor['TIME_ORIGIN'])))\n",
    "    \n",
    "    return offsets if offsets else None\n",
    "\n",
    "\n",
    "def format_time(seconds, offset=0):\n",
    "    \"\"\"Helper function to format time in SRT format (HH:MM:SS,ms)\"\"\"\n",
    "    seconds += offset / 1000  # Convert milliseconds to seconds\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    whole_seconds = int(seconds % 60)\n",
    "    milliseconds = int((seconds % 1) * 1000)  \n",
    "    return f\"{hours:02}:{minutes:02}:{whole_seconds:02},{milliseconds:03}\"\n",
    "\n",
    "\n",
    "def extend_annotations_with_priority(annotations, min_duration=0.5, start_buffer=0.1, end_buffer=0.5):\n",
    "    \n",
    "    # Sort annotations by start time\n",
    "    annotations.sort(key=lambda x: x['start'])\n",
    "\n",
    "    # Calculate durations\n",
    "    for ann in annotations:\n",
    "        ann['duration'] = ann['end'] - ann['start']\n",
    "    \n",
    "    # Pass 1: Extend annotations shorter than min_duration\n",
    "    for i, ann in enumerate(annotations):\n",
    "        if ann['duration'] < min_duration:\n",
    "            buffer = min_duration - ann['duration']\n",
    "            ann['start'] = max(0, ann['start'] - buffer * 0.5)\n",
    "            ann['end'] += buffer * 0.5\n",
    "            if i < len(annotations) - 1:\n",
    "                next_ann = annotations[i + 1]\n",
    "                if ann['end'] > next_ann['start']:\n",
    "                    ann['end'] = next_ann['start']\n",
    "\n",
    "    # Pass 2: Add half start_buffer where possible\n",
    "    for i, ann in enumerate(annotations):\n",
    "        buffer = start_buffer * 0.5\n",
    "        ann['start'] = max(0, ann['start'] - buffer)\n",
    "        if i > 0:\n",
    "            prev_ann = annotations[i - 1]\n",
    "            if ann['start'] < prev_ann['end']:\n",
    "                ann['start'] = prev_ann['end']\n",
    "\n",
    "    # Pass 3: Add full end_buffer and half start_buffer where possible\n",
    "    for i, ann in enumerate(annotations):\n",
    "        ann['end'] += end_buffer\n",
    "        ann['start'] = max(0, ann['start'] - start_buffer * 0.5)\n",
    "        if i < len(annotations) - 1:\n",
    "            next_ann = annotations[i + 1]\n",
    "            if ann['end'] > next_ann['start']:\n",
    "                ann['end'] = next_ann['start']\n",
    "        if i > 0:\n",
    "            prev_ann = annotations[i - 1]\n",
    "            if ann['start'] < prev_ann['end']:\n",
    "                ann['start'] = prev_ann['end']\n",
    "\n",
    "    \n",
    "    # Remove temporary keys\n",
    "    for ann in annotations:\n",
    "        del ann['duration']\n",
    "\n",
    "    return annotations\n",
    "\n",
    "def format_annotation(annotation):\n",
    "    # Use regex to find and replace ADD-TO-SIGNBANK(...) wrapper\n",
    "    pattern = r'ADD-TO-SIGNBANK\\((.*?)\\)'    \n",
    "    def replacement(match):\n",
    "        return match.group(1).strip()\n",
    "    annotation = re.sub(pattern, replacement, annotation)\n",
    "    \n",
    "    # Replace pronouns with more english translations\n",
    "    # Personal Pronouns:\n",
    "    \n",
    "    \n",
    "    annotation = annotation.replace(\"PT:PRO1SG\", \"I/me\")\n",
    "    annotation = annotation.replace(\"PT:PRO2SG\", \"you\")\n",
    "    annotation = annotation.replace(\"PT:PRO3SG\", \"he/she/it\")\n",
    "    annotation = annotation.replace(\"PT:PRO1PL\", \"we/us\")\n",
    "    annotation = annotation.replace(\"PT:PRO2PL\", \"you(pl)\")\n",
    "    annotation = annotation.replace(\"PT:PRO3PL\", \"they/them\")\n",
    "\n",
    "    annotation = annotation.replace(\"PRO1SG\", \"I/me\")\n",
    "    annotation = annotation.replace(\"PRO2SG\", \"you\")\n",
    "    annotation = annotation.replace(\"PRO3SG\", \"he/she/it\")\n",
    "    annotation = annotation.replace(\"PRO1PL\", \"we/us\")\n",
    "    annotation = annotation.replace(\"PRO2PL\", \"you(pl)\")\n",
    "    annotation = annotation.replace(\"PRO3PL\", \"they/them\")\n",
    "    # Possessive Pronouns:\n",
    "    annotation = annotation.replace(\"POSS1SG\", \"my/mine\")\n",
    "    annotation = annotation.replace(\"POSS2SG\", \"your/yours\")\n",
    "    annotation = annotation.replace(\"POSS3SG\", \"his/her/it\")\n",
    "    annotation = annotation.replace(\"POSS1PL\", \"our/ours\")\n",
    "    annotation = annotation.replace(\"POSS2PL\", \"your/yours\")\n",
    "    annotation = annotation.replace(\"POSS3PL\", \"their/theirs\")\n",
    "    annotation = annotation.replace(\"PT:my/mine\", \"my/mine\")\n",
    "\n",
    "    annotation = annotation.replace(\"PT:BODY\",\"(points to body)\") #  Point to a body part\n",
    "    annotation = annotation.replace(\"PT:LBUOY\",\"(points to list)\") # Point to a list buoy\n",
    "    annotation = annotation.replace(\"PT:FBUOY\",\"(points to fragment)\") # Point to a fragment buoy\n",
    "    annotation = annotation.replace(\"PT:BUOY\",\"(points)\") # Point to a buoy (of unspecified type)*\n",
    "    annotation = annotation.replace(\"PT:\", \"(points)\")\n",
    "\n",
    "   # annotation = annotation.replace(\"LBUOY-ONE\", \"(list)\")\n",
    "   # annotation = annotation.replace(\"LBUOY-TWO\", \"(list)\")\n",
    "   # annotation = annotation.replace(\"LBUOY-THREE\", \"(list)\")\n",
    "\n",
    "#    if \"BUOY\" in annotation:\n",
    " #       print(annotation)\n",
    "    \n",
    "\n",
    "    # Remove number suffixes\n",
    "    annotation = re.sub(r'\\d+$', '', annotation)\n",
    "   \n",
    "    return annotation\n",
    "\n",
    "            \n",
    "def get_tier_names(eaf_filename):\n",
    "    \"\"\"\n",
    "    Returns a list of tier names from an EAF file.\n",
    "    \n",
    "    Parameters:\n",
    "    eaf_filename (str): Path to the EAF file\n",
    "    \n",
    "    Returns:\n",
    "    list: List of tier names\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the EAF file\n",
    "        eaf = pympi.Elan.Eaf(eaf_filename)\n",
    "        \n",
    "        # Get tier names\n",
    "        tier_names = eaf.get_tier_names()\n",
    "        \n",
    "        return tier_names\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading EAF file: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "    \n",
    "def eaf_to_srt_combined(eaf_file, srt_file, offset):\n",
    "    eaf = pympi.Elan.Eaf(eaf_file)\n",
    "    \n",
    "    # Collect all annotations from RH and LH tiers\n",
    "    annotations = []\n",
    "    for tier_name in ['RH-IDgloss', 'LH-IDgloss']:\n",
    "        for annotation in eaf.get_annotation_data_for_tier(tier_name):\n",
    "            annotations.append({\n",
    "                'tier': tier_name,\n",
    "                'start': annotation[0],\n",
    "                'end': annotation[1],\n",
    "                'text': format_annotation(annotation[2])\n",
    "            })\n",
    "    \n",
    "    # Sort annotations by start time\n",
    "    annotations.sort(key=lambda x: x['start'])\n",
    "    \n",
    "    # Merge overlapping annotations\n",
    "    merged_annotations = []\n",
    "    current_annotation = None\n",
    "    for annotation in annotations:\n",
    "        if current_annotation is None or annotation['start'] > current_annotation['end']:\n",
    "            if current_annotation:\n",
    "                merged_annotations.append(current_annotation)\n",
    "            current_annotation = {\n",
    "                'start': annotation['start'],\n",
    "                'end': annotation['end'],\n",
    "                'rh_text': '',\n",
    "                'lh_text': ''\n",
    "            }\n",
    "        current_annotation['end'] = max(current_annotation['end'], annotation['end'])\n",
    "        if annotation['tier'] == 'RH-IDgloss':\n",
    "            current_annotation['rh_text'] = annotation['text']\n",
    "        else:\n",
    "            current_annotation['lh_text'] = annotation['text']\n",
    "    \n",
    "    if current_annotation:\n",
    "        merged_annotations.append(current_annotation)\n",
    "    \n",
    "    # Write to SRT file\n",
    "    overall_start_time=None\n",
    "    overall_end_time=None\n",
    "    with open(srt_file, 'w', encoding='utf-8') as f:\n",
    "        for index, annotation in enumerate(merged_annotations, 1):\n",
    "            # annotation is: 'start', 'end', 'rh_text', 'lh_text'\n",
    "            start_time = annotation['start'] / 1000\n",
    "            end_time = annotation['end'] / 1000\n",
    "            \n",
    "            if overall_start_time is None:\n",
    "                overall_start_time = start_time\n",
    "            overall_end_time = end_time\n",
    "            \n",
    "            # Combine RH and LH texts, with RH first\n",
    "            text = annotation['rh_text']\n",
    "            \n",
    "            if \"BUOY\" in annotation['lh_text'] or \"BUOY\" in annotation['rh_text']:\n",
    "                print(annotation['lh_text'], annotation['rh_text'])\n",
    "            if annotation['lh_text'] and annotation['lh_text'] != annotation['rh_text']:\n",
    "                text += ' | ' + annotation['lh_text']\n",
    "            \n",
    "            f.write(f\"{index}\\n\")\n",
    "            f.write(f\"{format_time(start_time, offset)} --> {format_time(end_time, offset)}\\n\")\n",
    "            f.write(f\"{text}\\n\\n\")\n",
    "    print(f\"Found {printable_time(overall_start_time, overall_end_time)} of subtitles from {format_time(overall_start_time, offset)} to {format_time(overall_end_time, offset)} \")\n",
    "\n",
    "def printable_time(start_time, end_time):\n",
    "    seconds = end_time-start_time\n",
    "    if (seconds < 60):\n",
    "        return f\"{seconds:.0f} seconds\"\n",
    "    else:\n",
    "        minutes = seconds/60.0\n",
    "        return  f\"{minutes:.2f} minutes\"\n",
    "\n",
    "def eaf_to_srt(eaf_file, srt_file, tier_name, offset):\n",
    "    eaf = pympi.Elan.Eaf(eaf_file)\n",
    "    overall_start_time=None\n",
    "    overall_end_time=None\n",
    "    \n",
    "    with open(srt_file, 'w', encoding='utf-8') as f:\n",
    "        index = 1\n",
    "        annotations = eaf.get_annotation_data_for_tier(tier_name)\n",
    "        for annotation in annotations:\n",
    "            start_time = annotation[0] / 1000\n",
    "            end_time = annotation[1] / 1000\n",
    "            text = format_annotation(annotation[2])\n",
    "            \n",
    "            if overall_start_time is None:\n",
    "                overall_start_time = start_time\n",
    "            overall_end_time = end_time            \n",
    "            \n",
    "            f.write(f\"{index}\\n\")\n",
    "            f.write(f\"{format_time(start_time, offset)} --> {format_time(end_time, offset)}\\n\")\n",
    "            f.write(f\"{text}\\n\\n\")\n",
    "            index += 1\n",
    "    \n",
    "    print(f\"Found {printable_time(overall_start_time, overall_end_time)} of subtitles from {format_time(overall_start_time, offset)} to {format_time(overall_end_time, offset)} \")\n",
    "\n",
    "\n",
    "def process_file(eaf_file):\n",
    "\n",
    "    srt_file_bsl = eaf_file.replace(\".eaf\", \".bsl.srt\")\n",
    "    srt_file_en = eaf_file.replace(\".eaf\", \".en.srt\")\n",
    "\n",
    "    tiers = get_tier_names(eaf_file)\n",
    "    #print(\"Found tiers:\")\n",
    "    #print(tiers)\n",
    "    offsets = get_all_time_offsets(eaf_file)\n",
    "    if (offsets is None):\n",
    "        offset = 0\n",
    "    elif (len(offsets)>1):\n",
    "    #    print(\"Multiple offsets found:\")\n",
    "    #    print(offsets)\n",
    "        offset = offsets[0]\n",
    "    else:\n",
    "        offset = offsets[0]\n",
    "\n",
    "    print(\"Using time offset: \"+str(offset))\n",
    "\n",
    "\n",
    "    # Example usage\n",
    "    english='Free Translation'\n",
    "    if (english in tiers):\n",
    "        print(\"Extracting english subtitles\")\n",
    "        eaf_to_srt(eaf_file, srt_file_en, 'Free Translation', offset)\n",
    "\n",
    "    print(\"Extracting BSL subtitles\")\n",
    "    eaf_to_srt_combined(eaf_file, srt_file_bsl, offset)\n",
    "\n",
    "process_file('inputs/BF10n.eaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0e5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3e1f4cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "inputs/BF24n.eaf\n",
      "Using time offset: 4720\n",
      "Extracting english subtitles\n",
      "Found 5.80 minutes of subtitles from 00:00:04,723 to 00:05:52,610 \n",
      "Extracting BSL subtitles\n",
      "Found 48 seconds of subtitles from 00:00:04,723 to 00:00:52,710 \n",
      "----------------\n",
      "inputs/BF12n.eaf\n",
      "Using time offset: 1635\n",
      "Extracting english subtitles\n",
      "Found 3.45 minutes of subtitles from 00:01:32,001 to 00:04:58,711 \n",
      "Extracting BSL subtitles\n",
      "Found 2.48 minutes of subtitles from 00:00:01,696 to 00:02:30,742 \n",
      "----------------\n",
      "inputs/BF13n.eaf\n",
      "Using time offset: 18106\n",
      "Extracting english subtitles\n",
      "Found 5.48 minutes of subtitles from 00:01:55,972 to 00:07:25,046 \n",
      "Extracting BSL subtitles\n",
      "Found 3.65 minutes of subtitles from 00:00:19,706 to 00:03:58,448 \n",
      "----------------\n",
      "inputs/BF25n.eaf\n",
      "Using time offset: 88\n",
      "Extracting english subtitles\n",
      "Found 3.85 minutes of subtitles from 00:00:01,598 to 00:03:52,567 \n",
      "Extracting BSL subtitles\n",
      "LBUOY-TWO (points to list)\n",
      "Found 54 seconds of subtitles from 00:00:00,852 to 00:00:54,762 \n",
      "----------------\n",
      "inputs/BF14n.eaf\n",
      "Using time offset: 815\n",
      "Extracting english subtitles\n",
      "Found 3.06 minutes of subtitles from 00:00:02,556 to 00:03:06,340 \n",
      "Extracting BSL subtitles\n",
      "(points to list) LBUOY-TWO\n",
      "(points to list) LBUOY-TWO\n",
      "Found 46 seconds of subtitles from 00:00:00,818 to 00:00:47,057 \n",
      "----------------\n",
      "inputs/BF18n.eaf\n",
      "Using time offset: 2226\n",
      "Extracting english subtitles\n",
      "Found 2.16 minutes of subtitles from 00:02:56,841 to 00:05:06,266 \n",
      "Extracting BSL subtitles\n",
      "Found 56 seconds of subtitles from 00:02:56,841 to 00:03:53,237 \n",
      "----------------\n",
      "inputs/BF22n.eaf\n",
      "Using time offset: 515\n",
      "Extracting english subtitles\n",
      "Found 8.46 minutes of subtitles from 00:00:00,918 to 00:08:28,534 \n",
      "Extracting BSL subtitles\n",
      "Found 4.87 minutes of subtitles from 00:00:00,918 to 00:04:53,110 \n",
      "----------------\n",
      "inputs/BF23n.eaf\n",
      "Using time offset: 10841\n",
      "Extracting english subtitles\n",
      "Found 4.19 minutes of subtitles from 00:01:40,916 to 00:05:52,081 \n",
      "Extracting BSL subtitles\n",
      "LBUOY-TWO (points to list)\n",
      "LBUOY-THREE (points to list)\n",
      "LBUOY-TWO (points to list)\n",
      "LBUOY-FOUR (points to list)\n",
      "Found 3.41 minutes of subtitles from 00:01:10,796 to 00:04:35,625 \n",
      "----------------\n",
      "inputs/BF19n.eaf\n",
      "Using time offset: 5646\n",
      "Extracting english subtitles\n",
      "Found 2.76 minutes of subtitles from 00:00:06,625 to 00:02:52,495 \n",
      "Extracting BSL subtitles\n",
      "Found 41 seconds of subtitles from 00:00:05,655 to 00:00:46,700 \n",
      "----------------\n",
      "inputs/BF15n.eaf\n",
      "Using time offset: 9810\n",
      "Extracting english subtitles\n",
      "Found 5.73 minutes of subtitles from 00:00:50,975 to 00:06:34,793 \n",
      "Extracting BSL subtitles\n",
      "Found 3.60 minutes of subtitles from 00:00:11,358 to 00:03:47,311 \n",
      "----------------\n",
      "inputs/BF20n.eaf\n",
      "Using time offset: 9460\n",
      "Extracting english subtitles\n",
      "Found 1.48 minutes of subtitles from 00:01:57,122 to 00:03:26,034 \n",
      "Extracting BSL subtitles\n",
      "Found 2.57 minutes of subtitles from 00:00:10,844 to 00:02:45,298 \n",
      "----------------\n",
      "inputs/BF21n.eaf\n",
      "Using time offset: 263\n",
      "Extracting english subtitles\n",
      "Found 8.65 minutes of subtitles from 00:00:01,333 to 00:08:40,173 \n",
      "Extracting BSL subtitles\n",
      "PBUOY (points)LOC\n",
      "PBUOY WHICH\n",
      "Found 50 seconds of subtitles from 00:00:01,349 to 00:00:51,295 \n",
      "----------------\n",
      "inputs/BF17n.eaf\n",
      "Using time offset: 4990\n",
      "Extracting english subtitles\n",
      "Found 5.08 minutes of subtitles from 00:00:05,502 to 00:05:10,513 \n",
      "Extracting BSL subtitles\n",
      "Found 35 seconds of subtitles from 00:00:05,250 to 00:00:39,795 \n",
      "----------------\n",
      "inputs/BF10n.eaf\n",
      "Using time offset: 2960\n",
      "Extracting english subtitles\n",
      "Found 2.26 minutes of subtitles from 00:00:02,960 to 00:02:18,597 \n",
      "Extracting BSL subtitles\n",
      "LBUOY-ONE (points to list)\n",
      "LBUOY-FIVE (points to list)\n",
      "LBUOY-FIVE (points to list)\n",
      "LBUOY-ONE (points to list)\n",
      "LBUOY-FIVE (points to list)\n",
      "LBUOY-FIVE (points to list)\n",
      "Found 1.15 minutes of subtitles from 00:00:02,973 to 00:01:12,040 \n",
      "----------------\n",
      "inputs/BF11n.eaf\n",
      "Using time offset: 0\n",
      "Extracting english subtitles\n",
      "Found 1.46 minutes of subtitles from 00:00:02,217 to 00:01:29,832 \n",
      "Extracting BSL subtitles\n",
      "Found 46 seconds of subtitles from 00:00:01,104 to 00:00:46,777 \n",
      "----------------\n",
      "inputs/BF1n.eaf\n",
      "Using time offset: 3661\n",
      "Extracting english subtitles\n",
      "Found 3.05 minutes of subtitles from 00:00:03,661 to 00:03:06,695 \n",
      "Extracting BSL subtitles\n",
      "LBUOY-TWO (points to list)\n",
      "LBUOY-TWO (points to list)\n",
      "LBUOY-TWO (points to list)\n",
      "LBUOY-TWO (points to list)\n",
      "LBUOY-TWO (points to list)\n",
      "Found 36 seconds of subtitles from 00:00:03,661 to 00:00:39,402 \n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "for file in glob.glob('inputs/*.eaf'):\n",
    "    print(\"-\"*16)\n",
    "    print(file)\n",
    "    process_file(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "745625cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 0.8999999999999999, 'end': 2.45, 'rh_text': 'Hello', 'lh_text': 'World'}\n",
      "{'start': 2.45, 'end': 4.0, 'rh_text': 'How', 'lh_text': 'are you?'}\n",
      "{'start': 4.655, 'end': 5.755, 'rh_text': 'wibble', 'lh_text': ''}\n",
      "{'start': 5.9, 'end': 7.5, 'rh_text': 'Good', 'lh_text': 'morning'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example usage\n",
    "annotations = [\n",
    "    {'start': 1.0, 'end': 2.0, 'rh_text': 'Hello', 'lh_text': 'World'},\n",
    "    {'start': 2.5, 'end': 3.5, 'rh_text': 'How', 'lh_text': 'are you?'},\n",
    "    {'start': 5, 'end': 5.01, 'rh_text': 'wibble', 'lh_text': ''},\n",
    "    {'start': 6.0, 'end': 7.0, 'rh_text': 'Good', 'lh_text': 'morning'}\n",
    "]\n",
    "\n",
    "extended_annotations = extend_annotations_with_priority(annotations)\n",
    "for annotation in extended_annotations:\n",
    "    print(annotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7fea0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Are we ready?\n",
      "- GOOD\n",
      "- I want to tell you about my puppy.\n",
      "- I/me\n",
      "- EXPLAIN\n",
      "- ABOUT\n",
      "- my/mine\n",
      "- FS:PUPPY\n",
      "- DSEW(FLAT)-BE:ANIMAL\n",
      "- My family got a puppy last year.\n",
      "- my/mine\n",
      "- WANT\n",
      "- FAMILY\n",
      "- AT-LAST\n",
      "- HAVE\n",
      "- DSEW(FLAT)-BE:ANIMAL\n",
      "- ?LAST-WEEK\n",
      "- GOOD\n",
      "- A new puppy, it's lovely.\n",
      "- NEW\n",
      "- DSEW(FLAT)-BE:ANIMAL\n",
      "- LOOK-GOOD\n",
      "- DSEW(FLAT)-BE:ANIMAL\n",
      "- G:WELL\n",
      "- My Dad had wanted a dog for a very long time\n",
      "- ?LAST-WEEK\n",
      "- TRUE\n",
      "- my/mine\n",
      "- FATHER\n",
      "- ALWAYS\n",
      "- WANT\n",
      "- | WANT\n",
      "- WANT\n",
      "- | WANT\n",
      "- DOG\n",
      "- WANT\n",
      "- | WANT\n",
      "- SINCE\n",
      "- Mum had said \"no, no, no, no\".\n",
      "- my/mine\n",
      "- MOTHER\n",
      "- ALWAYS\n",
      "- NO\n",
      "- NO\n",
      "- NO\n",
      "- NO\n",
      "- NO\n",
      "- FATHER\n",
      "- My Dad had been very patient\n",
      "- BEHAVIOUR\n",
      "- My Sister said to our Mum, \"It's not fair, Dad wants a dog\"\n",
      "- my/mine\n",
      "- SISTER\n",
      "- SAY\n",
      "- NO\n",
      "- EQUAL\n",
      "- my/mine\n",
      "- FATHER\n",
      "- WANT\n",
      "- DOG\n",
      "- G:WELL\n",
      "- My Mum still wasn't sure but then things settled down.\n",
      "- my/mine\n",
      "- MOTHER\n",
      "- G:ERM\n",
      "- G:WELL\n",
      "- SAME\n",
      "- SETTLE\n",
      "- SETTLE\n",
      "- my/mine\n",
      "- My sister got married and moved to England.\n",
      "- SISTER\n",
      "- MARRY\n",
      "- MOVE\n",
      "- SN:ENGLAND(ROYAL)\n",
      "- G:WELL\n",
      "- It seemed like the right time to get a dog.\n",
      "- WHY\n",
      "- NO\n",
      "- RIGHT\n",
      "- TIME\n",
      "- HAVE\n",
      "- DOG\n",
      "- SAY\n",
      "- She said, \"alright but there are two things.\"\n",
      "- ALRIGHT\n",
      "- DOG\n",
      "- BUT\n",
      "- TWO\n",
      "- (points to list) | LBUOY-TWO\n",
      "- (points to list) | LBUOY-TWO\n",
      "- Its hair mustn't fall anywhere at all.\n",
      "- MUST\n",
      "- NOTHING\n",
      "- HAIR\n",
      "- ?FALL\n",
      "- NOTHING\n",
      "- Because she didn't want to have to be vacuuming.\n",
      "- (points to list) | LBUOY-TWO\n",
      "- WHY\n",
      "- WANT\n",
      "- HOOVER\n",
      "- Secondly, it had to be small and not too big.\n",
      "- (points to list) | LBUOY-TWO\n",
      "- (points to list) | LBUOY-TWO\n",
      "- SMALL\n",
      "- NOT\n",
      "- BIG\n",
      "- G:WELL\n",
      "- My father said \"alright\" and started looking.\n",
      "- my/mine\n",
      "- FATHER\n",
      "- He found a Shih Tzu.\n",
      "- That's the name of the breed.\n",
      "- Their hairs don't fall and they are small, from China.\n",
      "- Beautiful.\n",
      "- My Dad looked in the newspaper and found a place just outside Ballymena where they breed them.\n",
      "- So, we drove over.\n",
      "- We met a man, in a shed.\n",
      "- He had six puppies, they were lovely.\n",
      "- The first dog that came up to us was ours!\n",
      "- Because it was the one that came to us first.\n",
      "- It came up, we had to take that one home!\n",
      "- With me in the back of the car, it was so small and lovely to stroke.\n",
      "- It was shy, nervous and tiny.\n",
      "- Just eight weeks old and so small.\n",
      "- I kept stroking the puppy.\n",
      "- We called her Honey.\n",
      "- Because her soft coat colour was ...\n",
      "- A girl, yes.\n",
      "- She had a honey coloured coat, so we called her \"Honey\".\n",
      "- We got home.\n",
      "- The first night, in our living room, Honey was under one of the chairs.\n",
      "- She looked frightened.\n",
      "- I think it was a new house.\n",
      "- She stayed hiding under the chair.\n",
      "- We tried to coax her out by stroking her.\n",
      "- Then she grew in confidence.\n",
      "- It has been one year now.\n",
      "- She's this big now.\n",
      "- She knows that we are Deaf.\n",
      "- That's great, because ...\n",
      "- If she looks and makes eye contact, we know that she's finished her water and she needs more by the way she looks up at us.\n",
      "- You know, to give her more water.\n",
      "- or, it's the door and she wants to go outside to the toilet.\n",
      "- You know by the look she gives, and I'll open the door.\n",
      "- In the living room there's a ledge in front of the window.\n",
      "- The dog loves to sit on there, watching outside.\n",
      "- She sits, looking up at it, then we lift her up there.\n",
      "- Her eye contact is so strong.\n",
      "- But with my Dad, she will bark as she knows my Dad can hear her barking.\n",
      "- But with my Mum and me, she uses eye contact.\n",
      "- It's great that she knows, really clever.\n",
      "- It's lovely!\n",
      "- She really loves my dad and he is definitely the master.\n",
      "- During the day she is fine with my Mum.\n",
      "- When my dad arrives home she follows him around everywhere.\n",
      "- She knows some signs as well.\n",
      "- Signs like: car, walk, food, as well as make up.\n",
      "- Every morning my mum goes over and signs \"make up\" to the dog, she wags her tail and gets all excited!\n",
      "- My mum lifts her up onto the table.\n",
      "- She lies down and gets brushed and sprayed.\n",
      "- It's brilliant!\n",
      "- She knows what the sign \"make up\" means and she wags her tail.\n",
      "- She gets brushed every morning.\n",
      "- Her coat must be brushed every day.\n",
      "- Before this, I never really had any great love of animals.\n",
      "- I didn't give them a thought.\n",
      "- When we got Honey, I became very attached, it was really lovely.\n",
      "- I recently watched a film with Mum and Dad, you know \"Lassie\"?\n",
      "- Well, I felt really emotional, but before, I wouldn't really have cared or paid it any attention.\n",
      "- Now, I am really fond of animals, because having a dog has made a difference.\n",
      "- She's lovely.\n",
      "- It has been one year now.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def parse_srt(file_path):\n",
    "    subtitles = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(0, len(lines), 4):\n",
    "            if i + 2 < len(lines):\n",
    "                time_range = lines[i + 1].strip()\n",
    "                text = lines[i + 2].strip()\n",
    "                start, end = time_range.split(' --> ')\n",
    "                start_time = datetime.strptime(start, '%H:%M:%S,%f')\n",
    "                end_time = datetime.strptime(end, '%H:%M:%S,%f')\n",
    "                subtitles.append({\n",
    "                    'start': start_time,\n",
    "                    'end': end_time,\n",
    "                    'text': text\n",
    "                })\n",
    "    return subtitles\n",
    "\n",
    "def process_subtitles(english_srt, bsl_srt):\n",
    "    english_subtitles = parse_srt(english_srt)\n",
    "    bsl_subtitles = parse_srt(bsl_srt)\n",
    "    \n",
    "    output = []\n",
    "    bsl_index = 0\n",
    "    \n",
    "    for english_sub in english_subtitles:\n",
    "        output.append(f\"- {english_sub['text']}\")\n",
    "        \n",
    "        while bsl_index < len(bsl_subtitles):\n",
    "            bsl_sub = bsl_subtitles[bsl_index]\n",
    "            if bsl_sub['start'] < english_sub['end'] and bsl_sub['end'] > english_sub['start']:\n",
    "                output.append(f\"- {bsl_sub['text']}\")\n",
    "                bsl_index += 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    # Add any remaining BSL subtitles\n",
    "    while bsl_index < len(bsl_subtitles):\n",
    "        output.append(f\"- {bsl_subtitles[bsl_index]['text']}\")\n",
    "        bsl_index += 1\n",
    "    \n",
    "    return '\\n'.join(output)\n",
    "\n",
    "# Usage\n",
    "english_srt = 'inputs/BF1n.en.srt'\n",
    "bsl_srt = 'inputs/BF1n.bsl.srt'\n",
    "result = process_subtitles(english_srt, bsl_srt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a025e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19257178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
