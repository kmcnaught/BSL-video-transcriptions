{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b559e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pympi\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b824f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "\n",
    "def get_all_time_offsets(eaf_file):\n",
    "    \n",
    "    offsets = []\n",
    "    eaf = pympi.Elan.Eaf(eaf_file)    \n",
    "\n",
    "    for media_descriptor in eaf.media_descriptors:\n",
    "        TIME_ORIGIN='TIME_ORIGIN'\n",
    "        if (TIME_ORIGIN in media_descriptor):\n",
    "            offsets.append(int((media_descriptor['TIME_ORIGIN'])))\n",
    "    \n",
    "    return offsets if offsets else None\n",
    "\n",
    "\n",
    "def format_time(seconds, offset=0):\n",
    "    \"\"\"Helper function to format time in SRT format (HH:MM:SS,ms)\"\"\"\n",
    "    seconds += offset / 1000  # Convert milliseconds to seconds\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    whole_seconds = int(seconds % 60)\n",
    "    milliseconds = int((seconds % 1) * 1000)  \n",
    "    return f\"{hours:02}:{minutes:02}:{whole_seconds:02},{milliseconds:03}\"\n",
    "\n",
    "\n",
    "def get_tier_names(eaf_filename):    \n",
    "    try:\n",
    "        # Load the EAF file\n",
    "        eaf = pympi.Elan.Eaf(eaf_filename)\n",
    "        \n",
    "        # Get tier names\n",
    "        tier_names = eaf.get_tier_names()\n",
    "        \n",
    "        return tier_names\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading EAF file: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "    \n",
    "def printable_time(start_time, end_time):\n",
    "    seconds = end_time-start_time\n",
    "    if (seconds < 60):\n",
    "        return f\"{seconds:.0f} seconds\"\n",
    "    else:\n",
    "        minutes = seconds/60.0\n",
    "        return  f\"{minutes:.2f} minutes\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7554a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_pronoun(annotation, sentence, pronoun_gloss, replacement_options):\n",
    "    # e.g. \"PT:PRO1SG\" is replaced by \"I\" or \"me\" depending\n",
    "    # which is present in the main sentence\n",
    "    gloss_present = None \n",
    "    if (\"PT:\"+pronoun_gloss) in annotation: \n",
    "        gloss_present = \"PT:\"+pronoun_gloss\n",
    "    elif pronoun_gloss in annotation: \n",
    "        gloss_present = pronoun_gloss\n",
    "    \n",
    "    if gloss_present is not None:\n",
    "        replacement_to_use = replacement_options[0]\n",
    "        for replacement in replacement_options:\n",
    "            if replacement in sentence:\n",
    "                replacement_to_use = replacement\n",
    "                break\n",
    "        return annotation.replace(gloss_present, replacement)\n",
    "    return annotation\n",
    "    \n",
    "\n",
    "def format_annotation(annotation, sentence):\n",
    "    # Use regex to find and replace ADD-TO-SIGNBANK(...) wrapper\n",
    "    pattern = r'ADD-TO-SIGNBANK\\((.*?)\\)'    \n",
    "    def replacement(match):\n",
    "        return match.group(1).strip()\n",
    "    annotation = re.sub(pattern, replacement, annotation)\n",
    "    \n",
    "    # Replace pronouns with more english translations\n",
    "    # Personal Pronouns:\n",
    "    \n",
    "    annotation = replace_pronoun(annotation, sentence, \"PRO1SG\", [\"I\", \"me\"])\n",
    "\n",
    "    annotation = replace_pronoun(annotation, sentence, \"PRO1SG\", [\"I\",\"me\"])\n",
    "    annotation = replace_pronoun(annotation, sentence, \"PRO2SG\", [\"you\",])\n",
    "    annotation = replace_pronoun(annotation, sentence, \"PRO3SG\", [\"he\",\"she\",\"it\"])\n",
    "    annotation = replace_pronoun(annotation, sentence, \"PRO1PL\", [\"we\",\"us\"])\n",
    "    annotation = replace_pronoun(annotation, sentence, \"PRO2PL\", [\"you(pl)\",])\n",
    "    annotation = replace_pronoun(annotation, sentence, \"PRO3PL\", [\"they/them\",])\n",
    "\n",
    "    annotation = replace_pronoun(annotation, sentence, \"POSS1SG\", [\"my\",\"mine\",])\n",
    "    annotation = replace_pronoun(annotation, sentence, \"POSS2SG\", [\"your\",\"yours\",])\n",
    "    annotation = replace_pronoun(annotation, sentence, \"POSS3SG\", [\"his\",\"her\",\"it\"])\n",
    "    annotation = replace_pronoun(annotation, sentence, \"POSS1PL\", [\"our\",\"ours\",])\n",
    "    annotation = replace_pronoun(annotation, sentence, \"POSS2PL\", [\"your\",\"yours\",])\n",
    "    annotation = replace_pronoun(annotation, sentence, \"POSS3PL\", [\"their\",\"theirs\",])\n",
    "\n",
    "    annotation = replace_pronoun(annotation, sentence, \"BODY\",[\"(points to body)\",]) #  Point to a body part\n",
    "    annotation = replace_pronoun(annotation, sentence, \"LBUOY\",[\"(points to list)\",]) # Point to a list buoy\n",
    "    annotation = replace_pronoun(annotation, sentence, \"FBUOY\",[\"(points to fragment)\",]) # Point to a fragment buoy\n",
    "    annotation = replace_pronoun(annotation, sentence, \"BUOY\",[\"(points)\",]) # Point to a buoy (of unspecified type)*\n",
    "    annotation = replace_pronoun(annotation, sentence, \"PT:\", [\"(points)\",])\n",
    "\n",
    "    annotation = annotation.replace(\"LBUOY-ONE\", \"(list 1)\")\n",
    "    annotation = annotation.replace(\"LBUOY-TWO\", \"(list 2)\")\n",
    "    annotation = annotation.replace(\"LBUOY-THREE\", \"(list 3)\")\n",
    "\n",
    "#    if \"BUOY\" in annotation:\n",
    " #       print(annotation)\n",
    "    \n",
    "\n",
    "    # Remove number suffixes\n",
    "    annotation = re.sub(r'\\d+$', '', annotation)\n",
    "   \n",
    "    return annotation \n",
    "\n",
    "def process_bsl(lh_gloss, rh_gloss, sentence):\n",
    "#     if (\"G:\" in lh_gloss):\n",
    "#         print(lh_gloss)\n",
    "#     if (\"G:\" in rh_gloss):\n",
    "#         print(rh_gloss)\n",
    "    lh_gloss = lh_gloss.strip()\n",
    "    rh_gloss = rh_gloss.strip()\n",
    "    \n",
    "    lh_gloss = format_annotation(lh_gloss, sentence)\n",
    "    rh_gloss = format_annotation(rh_gloss, sentence)\n",
    "\n",
    "    combined = \"\"\n",
    "    if (lh_gloss == rh_gloss):\n",
    "        combined = lh_gloss\n",
    "    elif lh_gloss and rh_gloss:\n",
    "        combined = lh_gloss + \" | \" + rh_gloss\n",
    "    elif lh_gloss:\n",
    "        combined = lh_gloss\n",
    "    elif rh_gloss:\n",
    "        combined = rh_gloss\n",
    "    \n",
    "    return combined\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de55d17b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using time offset: 2960\n",
      "Extracting BSL subtitles\n",
      "Okay?\n",
      "Right, hey.\n",
      "GOOD G:HEY\n",
      "I was pregnant, expecting.\n",
      "GOOD me G:HEY me\n",
      "I gave birth to a baby boy.\n",
      "I PREGNANT | EXPECT\n",
      "He grew and grew.\n",
      "BORN AT-LAST BABY BOY AND\n",
      "The mid-wife would visit me at home.\n",
      "?EXPAND FS:MID^SPOUSE\n",
      "That was to check the baby was alright, eating well etc. \n",
      "VISIT HOUSE\n",
      "I was patient.\n",
      "WHY CHECK BABY ALRIGHT EAT KNOW (points to list)-ONE | (points to list) (points to list)-FIVE | (points to list) me\n",
      "They came again the next week.\t\n",
      "I BEHAVIOUR AGAIN\n",
      "Very frustrating.\n",
      "COME NEXT-WEEK me\n",
      "They came again and again.\n",
      "STRESS COME\n",
      "After a while, they stopped.\n",
      "AND\n",
      "Now, with the baby bigger, I would take them to another place, like a hospital. \n",
      "?LATER FINISH\n",
      "They checked its weight and other things.\n",
      "NOW I BABY ?EXPAND MUST (points)LOC/he | I ?(points) | FROM-TO SAME HOSPITAL\n",
      "Fine.\n",
      "CHECK SCALES (points to list)-ONE | (points to list) (points to list)-FIVE | (points to list)\n",
      "Later on, a friend gave me a big pram.\n",
      "me GOOD AND\n",
      "I was delighted they had given it to me.\n",
      "LATER mine FRIEND GIVE MOW BIG me\n",
      "I thanked them a lot.\n",
      "I EXCITED GIVE EXCITED\n",
      "After they left, I lifted the baby into the pram.\n",
      "THANK ?FRIEND/AND\n",
      "It was sprung, really old fashioned, with a hood over it.\n",
      "GO I HUG BABY DSH(SPHERE)-MOVE/G:CA:PICKING-BABY-UP DSH(SPHERE)-MOVE/G:CA:PLACES-BABY-DOWN\n",
      "I pushed it along, to visit the mid-wife at the hospital.\n",
      "DSH(FIST)-MOVE/G:CA:MOVES-PRAM-UP-AND-DOWN OLD^FASHIONED DSS(SPHERE) UNKNOWN I\n",
      "The baby was to be weighed.\n",
      "DSH(FIST)-MOVE/G:CA-MOVES-PRAM-UP-AND-DOWN | DSH(FIST)-MOVE/G:CA:MOVES-PRAM-UP-AND-DOWN FEEL DSH(FIST)-MOVE/G:CA:MOVES-PRAM-UP-AND-DOWN VISIT FS:MID^SPOUSE (points)LOC HOSPITAL FOR\n",
      "I pushed the pram along.\n",
      "BABY SCALES G:WELL me\n",
      "I got really hot.\n",
      "I DSH(FIST)-MOVE/G:CA:MOVES-PRAM-SLOWLY\n",
      "I carried on pushing and got sweaty.\n",
      "HOT\n",
      "People were walking past me shivering.\n",
      "I DSH(FIST)-MOVE/G:CA:MOVES-PRAM-SLOWLY HOT G:CA:SWEATING-ON-FACE G:CA:SHAKES-TOP-TO-COOL-DOWN\n",
      "Created SRT file: inputs/BF10n.bsl.srt\n",
      "1.2 minutes of BSL\n",
      "2.3 minutes of english\n"
     ]
    }
   ],
   "source": [
    "def eaf_to_srt_combined(eaf_file, srt_file, offset):\n",
    "    eaf = pympi.Elan.Eaf(eaf_file)\n",
    "    \n",
    "    # Collect all annotations from RH and LH tiers\n",
    "    bsl_annotations = []\n",
    "    en_annotations = []\n",
    "    \n",
    "    for tier_name in ['RH-IDgloss', 'LH-IDgloss']:\n",
    "        for annotation in eaf.get_annotation_data_for_tier(tier_name):\n",
    "            bsl_annotations.append({\n",
    "                'tier': tier_name,\n",
    "                'start': annotation[0],\n",
    "                'end': annotation[1],\n",
    "                'text': annotation[2]\n",
    "            })\n",
    "    \n",
    "    for tier_name in ['Free Translation',]:\n",
    "        for annotation in eaf.get_annotation_data_for_tier(tier_name):\n",
    "            en_annotations.append({\n",
    "                'tier': tier_name,\n",
    "                'start': annotation[0],\n",
    "                'end': annotation[1],\n",
    "                'text': annotation[2]\n",
    "            })\n",
    "    \n",
    "    # Sort annotations by start time\n",
    "    en_annotations.sort(key=lambda x: x['start'])\n",
    "    bsl_annotations.sort(key=lambda x: x['start'])\n",
    "    \n",
    "    # Combine L and R BSL annotations, with reference to english translation\n",
    "    merged_annotations = []\n",
    "    for en_ann in en_annotations:\n",
    "        overlapping_bsl = [bsl_ann for bsl_ann in bsl_annotations \n",
    "                           if bsl_ann['start'] < en_ann['end'] and bsl_ann['end'] > en_ann['start']]\n",
    "        \n",
    "        current_annotation = None\n",
    "        for bsl_ann in overlapping_bsl:\n",
    "            if bsl_ann['tier'] == 'RH-IDgloss':\n",
    "                rh_gloss = bsl_ann['text']\n",
    "                lh_gloss = next((ann['text'] for ann in overlapping_bsl \n",
    "                                 if ann['tier'] == 'LH-IDgloss' and ann['start'] == bsl_ann['start']), '')\n",
    "            else:\n",
    "                lh_gloss = bsl_ann['text']\n",
    "                rh_gloss = next((ann['text'] for ann in overlapping_bsl \n",
    "                                 if ann['tier'] == 'RH-IDgloss' and ann['start'] == bsl_ann['start']), '')\n",
    "            \n",
    "            if current_annotation is None or (lh_gloss, rh_gloss) != (current_annotation['lh_gloss'], current_annotation['rh_gloss']):\n",
    "                if current_annotation:\n",
    "                    merged_annotations.append(current_annotation)\n",
    "                    \n",
    "                current_annotation = {\n",
    "                    'start': bsl_ann['start'],\n",
    "                    'end': bsl_ann['end'],\n",
    "                    'en_text': en_ann['text'],\n",
    "                    'lh_gloss': lh_gloss,\n",
    "                    'rh_gloss': rh_gloss\n",
    "                }\n",
    "            else:\n",
    "                current_annotation['end'] = max(current_annotation['end'], bsl_ann['end'])\n",
    "        \n",
    "        if current_annotation:\n",
    "            merged_annotations.append(current_annotation)\n",
    "    \n",
    "    # Combine the LH/RH glosses, based on context\n",
    "    for ann in merged_annotations:\n",
    "        ann['bsl'] = process_bsl(ann['lh_gloss'], ann['rh_gloss'], ann['en_text'])\n",
    "    \n",
    "    # Post-processing to merge duplicate BSL annotations\n",
    "    merged_annotations.sort(key=lambda x: x['start'])\n",
    "    processed_annotations = []\n",
    "    current_annotation = None\n",
    "    \n",
    "    for ann in merged_annotations:\n",
    "        if current_annotation is None or  \\\n",
    "            ann['bsl'] != current_annotation['bsl']:\n",
    "            if current_annotation:\n",
    "                processed_annotations.append(current_annotation)\n",
    "            current_annotation = ann.copy()\n",
    "        else:\n",
    "            current_annotation['end'] = max(current_annotation['end'], ann['end'])\n",
    "    \n",
    "    if current_annotation:\n",
    "        processed_annotations.append(current_annotation)\n",
    "    \n",
    "    # Post-processing to ensure minimum duration\n",
    "    final_annotations = []\n",
    "    min_duration = 0.3\n",
    "    for ann in processed_annotations:\n",
    "        duration = (ann['end'] - ann['start']) / 1000  # Convert to seconds\n",
    "        if duration < min_duration:\n",
    "            ann['end'] = ann['start'] + (min_duration * 1000)\n",
    "        final_annotations.append(ann)\n",
    "        \n",
    "    # Write to SRT file\n",
    "    current_sentence_en = None\n",
    "    current_sentence_bsl = None\n",
    "    first_bsl_time = None\n",
    "    with open(srt_file, 'w', encoding='utf-8') as f:\n",
    "        for index, ann in enumerate(final_annotations, 1):\n",
    "            start_time = ann['start'] / 1000\n",
    "            end_time = ann['end'] / 1000\n",
    "            \n",
    "            if (current_sentence_en != ann['en_text']):\n",
    "                current_sentence_en = ann['en_text']\n",
    "                print(current_sentence_en)\n",
    "         \n",
    "                # write previous sentence\n",
    "                if current_sentence_bsl is not None:\n",
    "                    f.write(f\"{index}\\n\")\n",
    "                    f.write(f\"{format_time(current_sentence_start, offset)} --> {format_time(end_time, offset)}\\n\")\n",
    "                    f.write(f\"{current_sentence_bsl}\\n\\n\")\n",
    "                    \n",
    "                    print(current_sentence_bsl)\n",
    "                current_sentence_bsl = \"\"\n",
    "                current_sentence_start = start_time\n",
    "                \n",
    "            else:\n",
    "                current_sentence_bsl += \" \"\n",
    "            current_sentence_bsl += ann[\"bsl\"]\n",
    "            \n",
    "            if first_bsl_time is None:\n",
    "                first_bsl_time = start_time\n",
    "                current_sentence_start = start_time\n",
    "                \n",
    "    last_bsl_end_time = end_time\n",
    "            \n",
    "    # Fall back to English when BSL annotations run out\n",
    "    with open(srt_file, 'a', encoding='utf-8') as f:\n",
    "        for index, ann in enumerate(en_annotations, 1):\n",
    "            start_time = ann['start'] / 1000\n",
    "            end_time = ann['end'] / 1000\n",
    "            \n",
    "            if start_time > last_bsl_end_time:\n",
    "                f.write(f\"{index}\\n\")\n",
    "                f.write(f\"{format_time(start_time, offset)} --> {format_time(end_time, offset)}\\n\")\n",
    "                english = ann['text']\n",
    "                f.write(f\"{english}\\n\\n\")\n",
    "    \n",
    "    \n",
    "    last_en_end_time = end_time\n",
    "    \n",
    "    print(f\"Created SRT file: {srt_file}\")\n",
    "    \n",
    "    print(f\"{(last_bsl_end_time - first_bsl_time)/60:.1f} minutes of BSL\")\n",
    "    print(f\"{(last_en_end_time - first_bsl_time)/60:.1f} minutes of english\")\n",
    "    \n",
    "    \n",
    "    \n",
    "def process_file(eaf_file):\n",
    "\n",
    "    srt_file_bsl = eaf_file.replace(\".eaf\", \".bsl.srt\")\n",
    "    srt_file_en = eaf_file.replace(\".eaf\", \".en.srt\")\n",
    "\n",
    "    tiers = get_tier_names(eaf_file)\n",
    "    offsets = get_all_time_offsets(eaf_file)\n",
    "    if (offsets is None):\n",
    "        offset = 0\n",
    "    elif (len(offsets)>1):\n",
    "        offset = offsets[0]\n",
    "    else:\n",
    "        offset = offsets[0]\n",
    "\n",
    "    print(\"Using time offset: \"+str(offset))\n",
    "\n",
    "    print(\"Extracting BSL subtitles\")\n",
    "    eaf_to_srt_combined(eaf_file, srt_file_bsl, offset)\n",
    "\n",
    "process_file('inputs/BF10n.eaf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c567ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f68188ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "inputs/BF24n.eaf\n",
      "Using time offset: 4720\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF24n.bsl.srt\n",
      "0.8 minutes of BSL\n",
      "5.8 minutes of english\n",
      "----------------\n",
      "inputs/BF12n.eaf\n",
      "Using time offset: 1635\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF12n.bsl.srt\n",
      "1.0 minutes of BSL\n",
      "3.4 minutes of english\n",
      "----------------\n",
      "inputs/BF13n.eaf\n",
      "Using time offset: 18106\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF13n.bsl.srt\n",
      "2.0 minutes of BSL\n",
      "5.5 minutes of english\n",
      "----------------\n",
      "inputs/BF25n.eaf\n",
      "Using time offset: 88\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF25n.bsl.srt\n",
      "0.9 minutes of BSL\n",
      "3.8 minutes of english\n",
      "----------------\n",
      "inputs/BF14n.eaf\n",
      "Using time offset: 815\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF14n.bsl.srt\n",
      "0.7 minutes of BSL\n",
      "3.1 minutes of english\n",
      "----------------\n",
      "inputs/BF18n.eaf\n",
      "Using time offset: 2226\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF18n.bsl.srt\n",
      "0.9 minutes of BSL\n",
      "2.2 minutes of english\n",
      "----------------\n",
      "inputs/BF22n.eaf\n",
      "Using time offset: 515\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF22n.bsl.srt\n",
      "4.9 minutes of BSL\n",
      "8.5 minutes of english\n",
      "----------------\n",
      "inputs/BF23n.eaf\n",
      "Using time offset: 10841\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF23n.bsl.srt\n",
      "2.9 minutes of BSL\n",
      "4.2 minutes of english\n",
      "----------------\n",
      "inputs/BF19n.eaf\n",
      "Using time offset: 5646\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF19n.bsl.srt\n",
      "0.7 minutes of BSL\n",
      "2.8 minutes of english\n",
      "----------------\n",
      "inputs/BF15n.eaf\n",
      "Using time offset: 9810\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF15n.bsl.srt\n",
      "2.9 minutes of BSL\n",
      "5.7 minutes of english\n",
      "----------------\n",
      "inputs/BF20n.eaf\n",
      "Using time offset: 9460\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF20n.bsl.srt\n",
      "0.8 minutes of BSL\n",
      "1.5 minutes of english\n",
      "----------------\n",
      "inputs/BF21n.eaf\n",
      "Using time offset: 263\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF21n.bsl.srt\n",
      "0.8 minutes of BSL\n",
      "8.6 minutes of english\n",
      "----------------\n",
      "inputs/BF17n.eaf\n",
      "Using time offset: 4990\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF17n.bsl.srt\n",
      "0.6 minutes of BSL\n",
      "5.1 minutes of english\n",
      "----------------\n",
      "inputs/BF10n.eaf\n",
      "Using time offset: 2960\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF10n.bsl.srt\n",
      "1.2 minutes of BSL\n",
      "2.3 minutes of english\n",
      "----------------\n",
      "inputs/BF11n.eaf\n",
      "Using time offset: 0\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF11n.bsl.srt\n",
      "0.7 minutes of BSL\n",
      "1.5 minutes of english\n",
      "----------------\n",
      "inputs/BF1n.eaf\n",
      "Using time offset: 3661\n",
      "Extracting BSL subtitles\n",
      "Created SRT file: inputs/BF1n.bsl.srt\n",
      "0.6 minutes of BSL\n",
      "3.1 minutes of english\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "for file in glob.glob('inputs/*.eaf'):\n",
    "    print(\"-\"*16)\n",
    "    print(file)\n",
    "    process_file(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77415cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 0.8999999999999999, 'end': 2.45, 'rh_text': 'Hello', 'lh_text': 'World'}\n",
      "{'start': 2.45, 'end': 4.0, 'rh_text': 'How', 'lh_text': 'are you?'}\n",
      "{'start': 4.655, 'end': 5.755, 'rh_text': 'wibble', 'lh_text': ''}\n",
      "{'start': 5.9, 'end': 7.5, 'rh_text': 'Good', 'lh_text': 'morning'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example usage\n",
    "annotations = [\n",
    "    {'start': 1.0, 'end': 2.0, 'rh_text': 'Hello', 'lh_text': 'World'},\n",
    "    {'start': 2.5, 'end': 3.5, 'rh_text': 'How', 'lh_text': 'are you?'},\n",
    "    {'start': 5, 'end': 5.01, 'rh_text': 'wibble', 'lh_text': ''},\n",
    "    {'start': 6.0, 'end': 7.0, 'rh_text': 'Good', 'lh_text': 'morning'}\n",
    "]\n",
    "\n",
    "extended_annotations = extend_annotations_with_priority(annotations)\n",
    "for annotation in extended_annotations:\n",
    "    print(annotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3adf6123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Are we ready?\n",
      "- GOOD\n",
      "- I want to tell you about my puppy.\n",
      "- I/me\n",
      "- EXPLAIN\n",
      "- ABOUT\n",
      "- my/mine\n",
      "- FS:PUPPY\n",
      "- DSEW(FLAT)-BE:ANIMAL\n",
      "- My family got a puppy last year.\n",
      "- my/mine\n",
      "- WANT\n",
      "- FAMILY\n",
      "- AT-LAST\n",
      "- HAVE\n",
      "- DSEW(FLAT)-BE:ANIMAL\n",
      "- ?LAST-WEEK\n",
      "- GOOD\n",
      "- A new puppy, it's lovely.\n",
      "- NEW\n",
      "- DSEW(FLAT)-BE:ANIMAL\n",
      "- LOOK-GOOD\n",
      "- DSEW(FLAT)-BE:ANIMAL\n",
      "- G:WELL\n",
      "- My Dad had wanted a dog for a very long time\n",
      "- ?LAST-WEEK\n",
      "- TRUE\n",
      "- my/mine\n",
      "- FATHER\n",
      "- ALWAYS\n",
      "- WANT\n",
      "- | WANT\n",
      "- WANT\n",
      "- | WANT\n",
      "- DOG\n",
      "- WANT\n",
      "- | WANT\n",
      "- SINCE\n",
      "- Mum had said \"no, no, no, no\".\n",
      "- my/mine\n",
      "- MOTHER\n",
      "- ALWAYS\n",
      "- NO\n",
      "- NO\n",
      "- NO\n",
      "- NO\n",
      "- NO\n",
      "- FATHER\n",
      "- My Dad had been very patient\n",
      "- BEHAVIOUR\n",
      "- My Sister said to our Mum, \"It's not fair, Dad wants a dog\"\n",
      "- my/mine\n",
      "- SISTER\n",
      "- SAY\n",
      "- NO\n",
      "- EQUAL\n",
      "- my/mine\n",
      "- FATHER\n",
      "- WANT\n",
      "- DOG\n",
      "- G:WELL\n",
      "- My Mum still wasn't sure but then things settled down.\n",
      "- my/mine\n",
      "- MOTHER\n",
      "- G:ERM\n",
      "- G:WELL\n",
      "- SAME\n",
      "- SETTLE\n",
      "- SETTLE\n",
      "- my/mine\n",
      "- My sister got married and moved to England.\n",
      "- SISTER\n",
      "- MARRY\n",
      "- MOVE\n",
      "- SN:ENGLAND(ROYAL)\n",
      "- G:WELL\n",
      "- It seemed like the right time to get a dog.\n",
      "- WHY\n",
      "- NO\n",
      "- RIGHT\n",
      "- TIME\n",
      "- HAVE\n",
      "- DOG\n",
      "- SAY\n",
      "- She said, \"alright but there are two things.\"\n",
      "- ALRIGHT\n",
      "- DOG\n",
      "- BUT\n",
      "- TWO\n",
      "- (points to list) | LBUOY-TWO\n",
      "- (points to list) | LBUOY-TWO\n",
      "- Its hair mustn't fall anywhere at all.\n",
      "- MUST\n",
      "- NOTHING\n",
      "- HAIR\n",
      "- ?FALL\n",
      "- NOTHING\n",
      "- Because she didn't want to have to be vacuuming.\n",
      "- (points to list) | LBUOY-TWO\n",
      "- WHY\n",
      "- WANT\n",
      "- HOOVER\n",
      "- Secondly, it had to be small and not too big.\n",
      "- (points to list) | LBUOY-TWO\n",
      "- (points to list) | LBUOY-TWO\n",
      "- SMALL\n",
      "- NOT\n",
      "- BIG\n",
      "- G:WELL\n",
      "- My father said \"alright\" and started looking.\n",
      "- my/mine\n",
      "- FATHER\n",
      "- He found a Shih Tzu.\n",
      "- That's the name of the breed.\n",
      "- Their hairs don't fall and they are small, from China.\n",
      "- Beautiful.\n",
      "- My Dad looked in the newspaper and found a place just outside Ballymena where they breed them.\n",
      "- So, we drove over.\n",
      "- We met a man, in a shed.\n",
      "- He had six puppies, they were lovely.\n",
      "- The first dog that came up to us was ours!\n",
      "- Because it was the one that came to us first.\n",
      "- It came up, we had to take that one home!\n",
      "- With me in the back of the car, it was so small and lovely to stroke.\n",
      "- It was shy, nervous and tiny.\n",
      "- Just eight weeks old and so small.\n",
      "- I kept stroking the puppy.\n",
      "- We called her Honey.\n",
      "- Because her soft coat colour was ...\n",
      "- A girl, yes.\n",
      "- She had a honey coloured coat, so we called her \"Honey\".\n",
      "- We got home.\n",
      "- The first night, in our living room, Honey was under one of the chairs.\n",
      "- She looked frightened.\n",
      "- I think it was a new house.\n",
      "- She stayed hiding under the chair.\n",
      "- We tried to coax her out by stroking her.\n",
      "- Then she grew in confidence.\n",
      "- It has been one year now.\n",
      "- She's this big now.\n",
      "- She knows that we are Deaf.\n",
      "- That's great, because ...\n",
      "- If she looks and makes eye contact, we know that she's finished her water and she needs more by the way she looks up at us.\n",
      "- You know, to give her more water.\n",
      "- or, it's the door and she wants to go outside to the toilet.\n",
      "- You know by the look she gives, and I'll open the door.\n",
      "- In the living room there's a ledge in front of the window.\n",
      "- The dog loves to sit on there, watching outside.\n",
      "- She sits, looking up at it, then we lift her up there.\n",
      "- Her eye contact is so strong.\n",
      "- But with my Dad, she will bark as she knows my Dad can hear her barking.\n",
      "- But with my Mum and me, she uses eye contact.\n",
      "- It's great that she knows, really clever.\n",
      "- It's lovely!\n",
      "- She really loves my dad and he is definitely the master.\n",
      "- During the day she is fine with my Mum.\n",
      "- When my dad arrives home she follows him around everywhere.\n",
      "- She knows some signs as well.\n",
      "- Signs like: car, walk, food, as well as make up.\n",
      "- Every morning my mum goes over and signs \"make up\" to the dog, she wags her tail and gets all excited!\n",
      "- My mum lifts her up onto the table.\n",
      "- She lies down and gets brushed and sprayed.\n",
      "- It's brilliant!\n",
      "- She knows what the sign \"make up\" means and she wags her tail.\n",
      "- She gets brushed every morning.\n",
      "- Her coat must be brushed every day.\n",
      "- Before this, I never really had any great love of animals.\n",
      "- I didn't give them a thought.\n",
      "- When we got Honey, I became very attached, it was really lovely.\n",
      "- I recently watched a film with Mum and Dad, you know \"Lassie\"?\n",
      "- Well, I felt really emotional, but before, I wouldn't really have cared or paid it any attention.\n",
      "- Now, I am really fond of animals, because having a dog has made a difference.\n",
      "- She's lovely.\n",
      "- It has been one year now.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def parse_srt(file_path):\n",
    "    subtitles = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(0, len(lines), 4):\n",
    "            if i + 2 < len(lines):\n",
    "                time_range = lines[i + 1].strip()\n",
    "                text = lines[i + 2].strip()\n",
    "                start, end = time_range.split(' --> ')\n",
    "                start_time = datetime.strptime(start, '%H:%M:%S,%f')\n",
    "                end_time = datetime.strptime(end, '%H:%M:%S,%f')\n",
    "                subtitles.append({\n",
    "                    'start': start_time,\n",
    "                    'end': end_time,\n",
    "                    'text': text\n",
    "                })\n",
    "    return subtitles\n",
    "\n",
    "def process_subtitles(english_srt, bsl_srt):\n",
    "    english_subtitles = parse_srt(english_srt)\n",
    "    bsl_subtitles = parse_srt(bsl_srt)\n",
    "    \n",
    "    output = []\n",
    "    bsl_index = 0\n",
    "    \n",
    "    for english_sub in english_subtitles:\n",
    "        output.append(f\"- {english_sub['text']}\")\n",
    "        \n",
    "        while bsl_index < len(bsl_subtitles):\n",
    "            bsl_sub = bsl_subtitles[bsl_index]\n",
    "            if bsl_sub['start'] < english_sub['end'] and bsl_sub['end'] > english_sub['start']:\n",
    "                output.append(f\"- {bsl_sub['text']}\")\n",
    "                bsl_index += 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    # Add any remaining BSL subtitles\n",
    "    while bsl_index < len(bsl_subtitles):\n",
    "        output.append(f\"- {bsl_subtitles[bsl_index]['text']}\")\n",
    "        bsl_index += 1\n",
    "    \n",
    "    return '\\n'.join(output)\n",
    "\n",
    "# Usage\n",
    "english_srt = 'inputs/BF1n.en.srt'\n",
    "bsl_srt = 'inputs/BF1n.bsl.srt'\n",
    "result = process_subtitles(english_srt, bsl_srt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e067dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f81f649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
